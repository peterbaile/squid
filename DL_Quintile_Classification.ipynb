{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL - Quintile Classification.ipynb",
      "provenance": [],
      "mount_file_id": "114OWqQMewuXGkxG8uDZPhlRPWeqxJtRH",
      "authorship_tag": "ABX9TyPv0WGGQlF4ffHY5Iy58h9O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peterbaile/squid/blob/master/DL_Quintile_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3R0hQULBhOOv"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import math\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.corpus import stopwords\n",
        "from tqdm import tqdm\n",
        "import string\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import sklearn\n",
        "\n",
        "tqdm.pandas()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3yE3GJY7SLq"
      },
      "source": [
        "Last Updated 2 Dec\n",
        "\n",
        "**Housekeeping**\n",
        "\n",
        "1. Download tensorflow_gpu (to enable much quicker training)\n",
        "2. Download eli5\n",
        "3. Download scikit-learn==0.21.3 (to enable text highlighting visualization of the eli5 explanations) https://github.com/TeamHG-Memex/eli5/issues/361\n",
        "\n",
        "**Workflow**\n",
        "\n",
        "1. Preprocessing raw text data\n",
        "2. Loading existing word embeddings to create embedding matrix\n",
        "3. Train RNN model (GRU) to classify documents into quintiles\n",
        "4. Evaluating Model (Confusion Matrix)\n",
        "5. Explainable Model Insights (contribution of each word to prediction)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wPjyw5RiRue",
        "outputId": "b0f9dddb-3137-4471-eff6-9e8f26a820d7"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U11V9cSUhW0f",
        "outputId": "71def5f5-b72f-4150-bd5f-e1a7c2b56161"
      },
      "source": [
        "tf.test.is_gpu_available()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-17bb7203622b>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3OEo7bkhW4u"
      },
      "source": [
        "train = pd.read_csv('drive/MyDrive/CIS520 Project/train.csv')\n",
        "content = train['content'].tolist()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73xtwczJhW-y"
      },
      "source": [
        "def preprocessing(content_list):\n",
        "    \n",
        "    processed_list = []\n",
        "    \n",
        "    for line in tqdm(content_list):\n",
        "        tokens = word_tokenize(line)\n",
        "        # Convert to lower case\n",
        "        tokens = [w.lower() for w in tokens]\n",
        "        # Remove punctuation\n",
        "        table = str.maketrans('', '', string.punctuation)\n",
        "        stripped = [w.translate(table) for w in tokens]\n",
        "        # Remove remaining tokens that are not alphabetic\n",
        "        words = [word for word in stripped if word.isalpha()]\n",
        "        # Filter out stopwords\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        words = [w for w in words if not w in stop_words]\n",
        "        \n",
        "        processed_list.append(words)\n",
        "        \n",
        "    return processed_list"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYR79wyJiC4k",
        "outputId": "cd62e4ab-95b9-4ca8-e780-c4f1c203c246"
      },
      "source": [
        "# Preprocessing the words\n",
        "train['processed_content'] = preprocessing(train['content'])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 16772/16772 [01:13<00:00, 226.80it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xo1RVhRiIq-"
      },
      "source": [
        "**Training Classification Model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti0OOP2qiC6r"
      },
      "source": [
        "# Extract the embeddings from the stored file\n",
        "# Embedding is size 111k (# words) x 100 (dimensions)\n",
        "import os \n",
        "\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "embeddings_index = {}\n",
        "f = open(os.path.join('drive/MyDrive/CIS520 Project', 'word2vec_train2.txt'), encoding = 'utf-8')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:])\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKtEWZGPiC8z"
      },
      "source": [
        "# Vectorize the text samples into 2D integer tensor\n",
        "tokenizer_obj = Tokenizer()\n",
        "# Fit the tokenizer on the text\n",
        "tokenizer_obj.fit_on_texts(train['processed_content'])\n",
        "# Generate the sequence of tokens\n",
        "sequences = tokenizer_obj.texts_to_sequences(train['processed_content'])\n",
        "\n",
        "# Get the max length of each article - 5587\n",
        "max_length = max([len(s) for s in train['processed_content']])\n",
        "# Get vocab size\n",
        "vocab_size = len(tokenizer_obj.word_index) + 1\n",
        "\n",
        "# Pad the sequences\n",
        "review_pad = pad_sequences(sequences, maxlen = max_length)\n",
        "\n",
        "word_index = tokenizer_obj.word_index"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Il2tcU_IiC_d",
        "outputId": "c601ca71-fddd-4046-d7a0-081c72ada3d8"
      },
      "source": [
        "num_words = len(word_index) + 1\n",
        "words_not_found = []\n",
        "# Create the emedding matrix - map embeddings from word2vec model for each word and create matrix of word vectors\n",
        "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    if i > num_words: # Least common words (don't care)\n",
        "        continue\n",
        "        \n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    \n",
        "    if (embedding_vector is not None):\n",
        "        # Assign the ith elmenet of the embedding matrix to the embedding of that word\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    else:\n",
        "        words_not_found.append(word)\n",
        "        \n",
        "print('number of null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of null word embeddings: 43\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtlyoMu0iDBZ",
        "outputId": "8dabc2fb-14c0-4469-b9e7-0755d95f5343"
      },
      "source": [
        "embedding_matrix.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(111813, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaUfltKdifxF"
      },
      "source": [
        "**Training DL Model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGElUT8bie6L"
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, Dense, Embedding, LSTM, GRU, SpatialDropout1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.initializers import Constant\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6BIoJTsie8l"
      },
      "source": [
        "def RNN_Model():\n",
        "    \n",
        "    text_sequence = Input(shape = (max_length,), name = 'text_sequence_input')\n",
        "    \n",
        "    rnn_layer = Embedding(num_words, EMBEDDING_DIM, weights = [embedding_matrix], trainable = False, name = 'embedding')(text_sequence)\n",
        "    \n",
        "    # Embedding Dropout\n",
        "    rnn_layer = SpatialDropout1D(0.25, name='EMBEDDING_DROPOUT')(rnn_layer)\n",
        "    rnn_layer = GRU(units = 32, dropout = 0.2)(rnn_layer)\n",
        "    output = Dense(5, activation = 'softmax', name = 'output')(rnn_layer)\n",
        "    \n",
        "    model = Model(inputs = text_sequence, outputs = output)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4KNwFnsie-s",
        "outputId": "440ab347-b389-4a3e-a5cb-8d79aa3fa5b3"
      },
      "source": [
        "model = RNN_Model()\n",
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_sequence_input (InputLa [(None, 5587)]            0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 5587, 100)         11181300  \n",
            "_________________________________________________________________\n",
            "EMBEDDING_DROPOUT (SpatialDr (None, 5587, 100)         0         \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 32)                12864     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 5)                 165       \n",
            "=================================================================\n",
            "Total params: 11,194,329\n",
            "Trainable params: 13,029\n",
            "Non-trainable params: 11,181,300\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1s3iIuWifAl",
        "outputId": "820ba4c5-b079-4334-a90e-8f86a225e6b3"
      },
      "source": [
        "# Getting the y-variable (Quintile classification)\n",
        "\n",
        "train['quintile'] = pd.cut(train['percentile'], [0, 0.2, 0.4, 0.6, 0.8, 1], labels = [1,2,3,4,5])\n",
        "train['quintile'] = train['quintile'].astype(int)\n",
        "\n",
        "# Split into train and validation set\n",
        "VALIDATION_SPLIT = 0.2\n",
        "dl_train, dl_val = train_test_split(train, test_size = VALIDATION_SPLIT, random_state = 42, stratify = train['quintile'])\n",
        "\n",
        "train_indices = dl_train.index.tolist()\n",
        "val_indices = dl_val.index.tolist()\n",
        "\n",
        "# Get the training and validation data\n",
        "X_train = review_pad[train_indices]\n",
        "X_val = review_pad[val_indices]\n",
        "\n",
        "#y_train = dl_train['quintile'].to_numpy()\n",
        "#y_val = dl_val['quintile'].to_numpy()\n",
        "\n",
        "# One Hot Encoding of y variable\n",
        "y_train = pd.get_dummies(dl_train['quintile']).to_numpy()\n",
        "y_val = pd.get_dummies(dl_val['quintile']).to_numpy()\n",
        "\n",
        "print('Shape of X_train: ', X_train.shape)\n",
        "print('Shape of y_train: ', y_train.shape)\n",
        "print('Shape of X_val: ', X_val.shape)\n",
        "print('Shape of y_val: ', y_val.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X_train:  (13417, 5587)\n",
            "Shape of y_train:  (13417, 5)\n",
            "Shape of X_val:  (3355, 5587)\n",
            "Shape of y_val:  (3355, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "XuUPAE3RiDFg",
        "outputId": "df852c02-d58a-482b-d472-49f69433dbe2"
      },
      "source": [
        "# Early stopping and model checkpoint\n",
        "early_stopping = EarlyStopping(monitor = 'val_categorical_accuracy', patience = 4, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    'model.h5', monitor='val_categorical_accuracy', verbose=0, save_best_only=True)\n",
        "\n",
        "# Train the DL Model\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['categorical_accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, batch_size = 32, epochs = 20, validation_data = (X_val, y_val), verbose = 1,\n",
        "         callbacks = [early_stopping, model_checkpoint])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "420/420 [==============================] - 86s 205ms/step - loss: 1.3048 - categorical_accuracy: 0.4251 - val_loss: 1.3657 - val_categorical_accuracy: 0.3878\n",
            "Epoch 2/20\n",
            "226/420 [===============>..............] - ETA: 35s - loss: 1.2900 - categorical_accuracy: 0.4369"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-24e237db4033>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m model.fit(X_train, y_train, batch_size = 32, epochs = 20, validation_data = (X_val, y_val), verbose = 1,\n\u001b[0;32m---> 10\u001b[0;31m          callbacks = [early_stopping, model_checkpoint])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1101\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \"\"\"\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m           \u001b[0mnumpy_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    531\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \"\"\"\n\u001b[1;32m   1062\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2djxslswCpw"
      },
      "source": [
        "# Save model\n",
        "model.save('drive/MyDrive/CIS520 Project/word2vec_gru_content1')"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qivgPNup7DJh"
      },
      "source": [
        "# Load model\n",
        "model = keras.models.load_model('drive/MyDrive/CIS520 Project/word2vec_gru_content1')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZ-oyBZZsT9Y"
      },
      "source": [
        "**Evaluating the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BNWEI4GsS2k"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhPD0gdTsS7j"
      },
      "source": [
        "# Predict on the validation data - returns (3355, 5) matrix of predicted classes\n",
        "val_probs = model.predict(X_val)\n",
        "# Predicted quintiles\n",
        "val_preds = np.argmax(val_probs, axis = 1)\n",
        "\n",
        "y_val_actual = np.argmax(y_val, axis = 1)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gC28NPm_7q7F",
        "outputId": "66241735-6da6-4c2b-ce98-343da5a5dc0b"
      },
      "source": [
        "# Confusion matrix\n",
        "confusion_matrix(y_val_actual, val_preds)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[450, 125,  33,  33,  24],\n",
              "       [232, 210,  86,  80,  62],\n",
              "       [109, 193, 105, 145, 117],\n",
              "       [ 43, 148, 100, 168, 213],\n",
              "       [ 21,  70,  54, 147, 387]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51NDD4XOvld6"
      },
      "source": [
        "The results show that while the accuracy is low (~40%), the errors are mostly off-by-1, and decline with greater difference between actual and predicted class, which is a good sign."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ypw2oWssv6Ws"
      },
      "source": [
        "**Model Interpretability using ELI5**\n",
        "\n",
        "(Needs to be installed first)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRH9hi1dyhUf"
      },
      "source": [
        "import eli5\n",
        "from eli5.lime import TextExplainer"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APNHBXZ6tEyy"
      },
      "source": [
        "# Define the custom predict function - input is list of strings (documents) and return matrix of shape (n_samples, n_classes) with probability values\n",
        "\n",
        "\n",
        "# Assumes you already fitted the tokenizer on the training data\n",
        "def predict_complex(documents_list):\n",
        "\n",
        "  # Generate the sequence of tokens\n",
        "  sequences = tokenizer_obj.texts_to_sequences(documents_list)\n",
        "\n",
        "  # Pad the sequences\n",
        "  X = pad_sequences(sequences, maxlen = 5587)\n",
        "\n",
        "  # Predict\n",
        "  y_probs = model.predict([X], batch_size = 32, verbose = 0)\n",
        "\n",
        "  # *** Convert this into a one-class classification of bottom 3 quintiles vs top 2 quintiles\n",
        "  y_high = y_probs[:, 3:].sum(axis = 1)\n",
        "  y_low = y_probs[:, 0:3].sum(axis = 1)\n",
        "\n",
        "  y_out = np.vstack((y_low, y_high)).T\n",
        "  return y_out\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "DYojM6wPtE1D",
        "outputId": "16e19357-57b9-40c4-991d-0b40d2dc3559"
      },
      "source": [
        "te = TextExplainer(random_state = 42)\n",
        "\n",
        "doc = ' '.join(dl_val['processed_content'].iloc[1])\n",
        "te.fit(doc, predict_complex)\n",
        "te.explain_prediction(target_names = ['low', 'high'])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=low\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.521</b>, score <b>-0.086</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.910\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 81.34%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.824\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 94.05%); opacity: 0.81\" title=\"0.020\">first</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 74.96%); opacity: 0.90\" title=\"0.157\">time</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.22%); opacity: 0.84\" title=\"0.067\">ever</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.47%); opacity: 0.84\" title=\"-0.065\">group</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.29%); opacity: 0.87\" title=\"-0.111\">secondyear</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.05%); opacity: 0.84\" title=\"-0.061\">mba</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.35%); opacity: 0.82\" title=\"-0.029\">students</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.86%); opacity: 0.81\" title=\"-0.008\">opportunity</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.74%); opacity: 0.84\" title=\"0.057\">study</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.72%); opacity: 0.82\" title=\"0.027\">abroad</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.11%); opacity: 0.80\" title=\"-0.004\">semester</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.94%); opacity: 0.86\" title=\"-0.098\">wharton</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 77.23%); opacity: 0.89\" title=\"0.137\">school</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.40%); opacity: 0.80\" title=\"0.006\">recently</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.20%); opacity: 0.81\" title=\"-0.019\">launched</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.37%); opacity: 0.82\" title=\"0.034\">pilot</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 76.89%); opacity: 0.89\" title=\"0.140\">program</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 76.21%); opacity: 0.90\" title=\"0.146\">conjunction</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.31%); opacity: 0.84\" title=\"-0.066\">new</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 77.53%); opacity: 0.89\" title=\"-0.134\">san</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.36%); opacity: 0.83\" title=\"-0.040\">francisco</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 76.21%); opacity: 0.90\" title=\"-0.146\">campus</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.65%); opacity: 0.81\" title=\"0.017\">opened</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.26%); opacity: 0.83\" title=\"0.047\">january</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.82%); opacity: 0.80\" title=\"0.005\">program</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.75%); opacity: 0.82\" title=\"-0.038\">select</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.06%); opacity: 0.84\" title=\"0.061\">group</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.57%); opacity: 0.81\" title=\"-0.022\">students</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.04%); opacity: 0.81\" title=\"-0.011\">able</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.16%); opacity: 0.87\" title=\"0.113\">study</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.14%); opacity: 0.82\" title=\"0.030\">school</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.31%); opacity: 0.83\" title=\"-0.053\">west</span><span style=\"opacity: 0.80\"> coast </span><span style=\"background-color: hsl(0, 100.00%, 86.38%); opacity: 0.84\" title=\"-0.066\">location</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.08%); opacity: 0.83\" title=\"-0.042\">fall</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.80%); opacity: 0.80\" title=\"0.005\">semester</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.50%); opacity: 0.81\" title=\"0.014\">program</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.99%); opacity: 0.83\" title=\"-0.042\">designed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.34%); opacity: 0.81\" title=\"-0.014\">give</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.75%); opacity: 0.81\" title=\"-0.022\">students</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.20%); opacity: 0.82\" title=\"-0.030\">opportunity</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.55%); opacity: 0.80\" title=\"-0.000\">immerse</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.86%); opacity: 0.81\" title=\"0.021\">entrepreneurial</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.04%); opacity: 0.83\" title=\"0.042\">technologyrich</span><span style=\"opacity: 0.80\"> environment </span><span style=\"background-color: hsl(120, 100.00%, 97.17%); opacity: 0.80\" title=\"0.007\">silicon</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.00%); opacity: 0.83\" title=\"0.048\">valley</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.16%); opacity: 0.88\" title=\"0.129\">semester</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.76%); opacity: 0.82\" title=\"-0.038\">application</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.57%); opacity: 0.84\" title=\"-0.064\">process</span><span style=\"opacity: 0.80\"> consisted </span><span style=\"background-color: hsl(120, 100.00%, 98.03%); opacity: 0.80\" title=\"0.004\">questions</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.73%); opacity: 0.82\" title=\"-0.038\">asking</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 75.60%); opacity: 0.90\" title=\"-0.151\">applicants</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 79.11%); opacity: 0.88\" title=\"-0.121\">describe</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.97%); opacity: 0.86\" title=\"-0.090\">career</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.19%); opacity: 0.81\" title=\"0.015\">goals</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.56%); opacity: 0.83\" title=\"-0.051\">explain</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.12%); opacity: 0.82\" title=\"0.025\">semester</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.03%); opacity: 0.84\" title=\"-0.068\">san</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.88%); opacity: 0.81\" title=\"-0.008\">francisco</span><span style=\"opacity: 0.80\"> would </span><span style=\"background-color: hsl(120, 100.00%, 91.66%); opacity: 0.82\" title=\"0.033\">help</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.63%); opacity: 0.82\" title=\"-0.033\">grow</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.87%); opacity: 0.81\" title=\"0.016\">addition</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.62%); opacity: 0.84\" title=\"-0.064\">students</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.84%); opacity: 0.81\" title=\"-0.021\">needed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.93%); opacity: 0.81\" title=\"0.016\">demonstrate</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.26%); opacity: 0.82\" title=\"0.035\">strong</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.31%); opacity: 0.87\" title=\"-0.103\">academic</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.05%); opacity: 0.85\" title=\"-0.075\">record</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 78.47%); opacity: 0.88\" title=\"-0.126\">wharton</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.27%); opacity: 0.84\" title=\"-0.060\">vice</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.54%); opacity: 0.86\" title=\"-0.086\">dean</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.08%); opacity: 0.88\" title=\"0.121\">innovation</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.71%); opacity: 0.82\" title=\"0.027\">karl</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.27%); opacity: 0.81\" title=\"-0.019\">ulrich</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.14%); opacity: 0.84\" title=\"0.067\">noted</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.59%); opacity: 0.83\" title=\"0.051\">benefits</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.50%); opacity: 0.83\" title=\"0.039\">implementing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.12%); opacity: 0.82\" title=\"0.025\">semester</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.03%); opacity: 0.84\" title=\"-0.068\">san</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.12%); opacity: 0.84\" title=\"-0.068\">francisco</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.74%); opacity: 0.83\" title=\"-0.044\">secondyear</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.05%); opacity: 0.84\" title=\"-0.061\">mba</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.45%); opacity: 0.82\" title=\"0.034\">students</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.65%); opacity: 0.82\" title=\"0.027\">blending</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.59%); opacity: 0.82\" title=\"0.028\">classroom</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.09%); opacity: 0.84\" title=\"0.054\">instruction</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.42%); opacity: 0.85\" title=\"-0.080\">extracurricular</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.36%); opacity: 0.86\" title=\"-0.088\">activities</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.70%); opacity: 0.82\" title=\"-0.032\">various</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.64%); opacity: 0.81\" title=\"0.017\">kinds</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.64%); opacity: 0.80\" title=\"0.005\">engagement</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.28%); opacity: 0.87\" title=\"-0.104\">regional</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 77.42%); opacity: 0.89\" title=\"-0.135\">economy</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.05%); opacity: 0.82\" title=\"-0.030\">hopefully</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.83%); opacity: 0.81\" title=\"0.016\">create</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.06%); opacity: 0.84\" title=\"0.061\">powerful</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.05%); opacity: 0.85\" title=\"-0.082\">cohesive</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.76%); opacity: 0.82\" title=\"-0.027\">educational</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.30%); opacity: 0.83\" title=\"-0.040\">experience</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.91%); opacity: 0.82\" title=\"-0.031\">said</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.43%); opacity: 0.88\" title=\"0.119\">order</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.89%); opacity: 0.83\" title=\"0.043\">develop</span><span style=\"opacity: 0.80\"> curriculum </span><span style=\"background-color: hsl(0, 100.00%, 86.03%); opacity: 0.84\" title=\"-0.068\">san</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.60%); opacity: 0.81\" title=\"-0.018\">francisco</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.51%); opacity: 0.81\" title=\"-0.013\">semester</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 76.79%); opacity: 0.89\" title=\"-0.141\">wharton</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.32%); opacity: 0.82\" title=\"-0.035\">took</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.40%); opacity: 0.81\" title=\"0.010\">students</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.57%); opacity: 0.84\" title=\"-0.064\">career</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 77.49%); opacity: 0.89\" title=\"-0.135\">course</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.04%); opacity: 0.84\" title=\"-0.055\">interests</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.21%); opacity: 0.85\" title=\"-0.081\">consideration</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.95%); opacity: 0.81\" title=\"-0.016\">curriculum</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.35%); opacity: 0.82\" title=\"-0.024\">fairly</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.74%); opacity: 0.80\" title=\"-0.005\">tightly</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.61%); opacity: 0.82\" title=\"-0.027\">integrated</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.82%); opacity: 0.82\" title=\"0.037\">terms</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.92%); opacity: 0.81\" title=\"0.021\">focus</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.05%); opacity: 0.82\" title=\"-0.036\">linking</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.05%); opacity: 0.82\" title=\"-0.036\">content</span><span style=\"opacity: 0.80\"> course </span><span style=\"background-color: hsl(120, 100.00%, 87.35%); opacity: 0.84\" title=\"0.059\">region</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.79%); opacity: 0.83\" title=\"0.050\">ways</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.28%); opacity: 0.80\" title=\"-0.007\">said</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.60%); opacity: 0.81\" title=\"-0.018\">based</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.96%); opacity: 0.87\" title=\"0.106\">affinity</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.16%); opacity: 0.82\" title=\"0.035\">students</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.37%); opacity: 0.82\" title=\"0.034\">ended</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.56%); opacity: 0.80\" title=\"-0.000\">curriculum</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.23%); opacity: 0.82\" title=\"-0.030\">much</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.13%); opacity: 0.81\" title=\"-0.011\">focused</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.74%); opacity: 0.81\" title=\"-0.022\">entrepreneurship</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.31%); opacity: 0.82\" title=\"0.029\">technology</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.84%); opacity: 0.80\" title=\"-0.002\">also</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.30%); opacity: 0.83\" title=\"-0.053\">main</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.93%); opacity: 0.85\" title=\"-0.083\">strengths</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.64%); opacity: 0.81\" title=\"-0.013\">bay</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.78%); opacity: 0.81\" title=\"0.008\">area</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 74.76%); opacity: 0.90\" title=\"-0.159\">according</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.13%); opacity: 0.86\" title=\"-0.089\">ulrich</span><span style=\"opacity: 0.80\"> course </span><span style=\"background-color: hsl(120, 100.00%, 94.19%); opacity: 0.81\" title=\"0.019\">particular</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.30%); opacity: 0.82\" title=\"-0.024\">focus</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.41%); opacity: 0.83\" title=\"-0.040\">featuring</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.71%); opacity: 0.82\" title=\"-0.038\">guest</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.18%); opacity: 0.84\" title=\"0.060\">speakers</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.03%); opacity: 0.84\" title=\"-0.068\">san</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.88%); opacity: 0.81\" title=\"-0.008\">francisco</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.28%); opacity: 0.82\" title=\"0.024\">talk</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.13%); opacity: 0.80\" title=\"-0.001\">professional</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.56%); opacity: 0.81\" title=\"0.023\">experiences</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.11%); opacity: 0.85\" title=\"0.075\">facility</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.10%); opacity: 0.81\" title=\"-0.011\">tours</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.77%); opacity: 0.81\" title=\"0.012\">also</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.81%); opacity: 0.81\" title=\"0.017\">part</span><span style=\"opacity: 0.80\"> curriculum </span><span style=\"background-color: hsl(120, 100.00%, 95.20%); opacity: 0.81\" title=\"0.015\">tour</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.76%); opacity: 0.87\" title=\"-0.100\">tesla</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.60%); opacity: 0.86\" title=\"-0.093\">motors</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.94%); opacity: 0.81\" title=\"-0.021\">fremont</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.42%); opacity: 0.80\" title=\"-0.006\">calif</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.71%); opacity: 0.86\" title=\"-0.085\">scheduled</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.21%); opacity: 0.82\" title=\"-0.035\">november</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.01%); opacity: 0.81\" title=\"0.016\">secondyear</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.19%); opacity: 0.83\" title=\"-0.047\">mba</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.19%); opacity: 0.81\" title=\"-0.019\">student</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.37%); opacity: 0.81\" title=\"-0.014\">rajeev</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.15%); opacity: 0.85\" title=\"-0.082\">jeyakumar</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.27%); opacity: 0.83\" title=\"-0.047\">one</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.73%); opacity: 0.83\" title=\"0.050\">participants</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.52%); opacity: 0.82\" title=\"0.033\">program</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.20%); opacity: 0.80\" title=\"0.004\">highlighted</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.55%); opacity: 0.81\" title=\"-0.018\">semester</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.63%); opacity: 0.83\" title=\"0.039\">conduciveness</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.15%); opacity: 0.81\" title=\"-0.011\">rising</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.05%); opacity: 0.82\" title=\"0.030\">entrepreneurs</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.11%); opacity: 0.80\" title=\"-0.007\">see</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.78%); opacity: 0.82\" title=\"-0.038\">ecosystem</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.33%); opacity: 0.82\" title=\"0.029\">entrepreneurial</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.99%); opacity: 0.80\" title=\"-0.004\">culture</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.90%); opacity: 0.84\" title=\"-0.062\">bay</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.78%); opacity: 0.81\" title=\"0.008\">area</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.84%); opacity: 0.81\" title=\"-0.016\">invaluable</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.95%); opacity: 0.86\" title=\"0.091\">even</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.87%); opacity: 0.85\" title=\"0.076\">going</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.78%); opacity: 0.86\" title=\"0.092\">stay</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.10%); opacity: 0.84\" title=\"0.054\">said</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.27%); opacity: 0.85\" title=\"-0.074\">jeyakumar</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.27%); opacity: 0.83\" title=\"-0.041\">plans</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.63%); opacity: 0.83\" title=\"0.039\">launch</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.07%); opacity: 0.86\" title=\"-0.090\">company</span><span style=\"opacity: 0.80\"> future </span><span style=\"background-color: hsl(0, 100.00%, 98.41%); opacity: 0.80\" title=\"-0.003\">also</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.13%); opacity: 0.84\" title=\"-0.054\">described</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.44%); opacity: 0.83\" title=\"0.046\">helpful</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.92%); opacity: 0.82\" title=\"-0.026\">friendly</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.57%); opacity: 0.81\" title=\"0.023\">atmosphere</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.51%); opacity: 0.84\" title=\"-0.065\">program</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.75%); opacity: 0.84\" title=\"-0.057\">already</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.72%); opacity: 0.87\" title=\"-0.100\">met</span><span style=\"opacity: 0.80\"> people </span><span style=\"background-color: hsl(0, 100.00%, 81.09%); opacity: 0.87\" title=\"-0.105\">willing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.69%); opacity: 0.84\" title=\"-0.057\">help</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.97%); opacity: 0.83\" title=\"0.042\">investors</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.02%); opacity: 0.81\" title=\"-0.016\">willing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.95%); opacity: 0.81\" title=\"-0.008\">give</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.61%); opacity: 0.84\" title=\"-0.057\">advice</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.78%); opacity: 0.81\" title=\"0.012\">said</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.39%); opacity: 0.80\" title=\"0.003\">accelerating</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.34%); opacity: 0.81\" title=\"0.019\">development</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.36%); opacity: 0.86\" title=\"-0.088\">process</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.36%); opacity: 0.86\" title=\"-0.088\">startups</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.36%); opacity: 0.81\" title=\"-0.010\">going</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.93%); opacity: 0.84\" title=\"0.055\">amazing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.28%); opacity: 0.84\" title=\"0.066\">katherine</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.11%); opacity: 0.85\" title=\"-0.082\">howell</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.43%); opacity: 0.83\" title=\"-0.046\">another</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.01%); opacity: 0.81\" title=\"0.016\">secondyear</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.19%); opacity: 0.83\" title=\"-0.047\">mba</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.48%); opacity: 0.81\" title=\"0.014\">student</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.00%); opacity: 0.80\" title=\"0.004\">program</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.70%); opacity: 0.82\" title=\"-0.038\">opportunity</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.08%); opacity: 0.83\" title=\"-0.042\">cultivate</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.66%); opacity: 0.82\" title=\"0.027\">relationships</span><span style=\"opacity: 0.80\"> west </span><span style=\"background-color: hsl(0, 100.00%, 87.26%); opacity: 0.84\" title=\"-0.060\">coast</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.02%); opacity: 0.83\" title=\"-0.042\">appealing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.19%); opacity: 0.81\" title=\"0.015\">aspect</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.11%); opacity: 0.80\" title=\"-0.001\">program</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.66%); opacity: 0.82\" title=\"0.027\">helps</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.68%); opacity: 0.81\" title=\"-0.009\">us</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.37%); opacity: 0.83\" title=\"-0.052\">develop</span><span style=\"opacity: 0.80\"> surrounded people </span><span style=\"background-color: hsl(120, 100.00%, 94.03%); opacity: 0.81\" title=\"0.020\">thinking</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.83%); opacity: 0.83\" title=\"0.043\">ideas</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.17%); opacity: 0.85\" title=\"-0.074\">feed</span><span style=\"opacity: 0.80\"> learn </span><span style=\"background-color: hsl(0, 100.00%, 82.89%); opacity: 0.86\" title=\"-0.091\">said</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.70%); opacity: 0.87\" title=\"-0.100\">surrounded</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.68%); opacity: 0.84\" title=\"0.064\">people</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.87%); opacity: 0.82\" title=\"0.026\">working</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.50%); opacity: 0.81\" title=\"-0.023\">areas</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.81%); opacity: 0.84\" title=\"-0.063\">experience</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.92%); opacity: 0.85\" title=\"-0.076\">definitely</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.01%); opacity: 0.82\" title=\"-0.031\">take</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.35%); opacity: 0.82\" title=\"-0.024\">advantage</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.20%); opacity: 0.82\" title=\"0.030\">jacob</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.08%); opacity: 0.80\" title=\"-0.004\">samuelson</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.33%); opacity: 0.80\" title=\"0.006\">added</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.41%); opacity: 0.84\" title=\"-0.059\">opportunity</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.33%); opacity: 0.81\" title=\"-0.014\">work</span><span style=\"opacity: 0.80\"> companies </span><span style=\"background-color: hsl(0, 100.00%, 98.94%); opacity: 0.80\" title=\"-0.002\">based</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.17%); opacity: 0.80\" title=\"0.007\">silicon</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.29%); opacity: 0.82\" title=\"-0.029\">valley</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.65%); opacity: 0.84\" title=\"0.064\">give</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.16%); opacity: 0.80\" title=\"-0.007\">students</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.73%); opacity: 0.83\" title=\"0.044\">unique</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.94%); opacity: 0.83\" title=\"-0.043\">firsthand</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.13%); opacity: 0.82\" title=\"0.036\">perspective</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.36%); opacity: 0.81\" title=\"-0.010\">going</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.87%); opacity: 0.82\" title=\"0.026\">work</span><span style=\"opacity: 0.80\"> education </span><span style=\"background-color: hsl(120, 100.00%, 94.16%); opacity: 0.81\" title=\"0.020\">technology</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.07%); opacity: 0.86\" title=\"-0.090\">company</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.59%); opacity: 0.83\" title=\"-0.045\">worked</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.44%); opacity: 0.82\" title=\"0.028\">last</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.24%); opacity: 0.83\" title=\"0.053\">summer</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.03%); opacity: 0.81\" title=\"-0.011\">based</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.50%); opacity: 0.82\" title=\"0.034\">samuelson</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.03%); opacity: 0.82\" title=\"0.036\">another</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.01%); opacity: 0.81\" title=\"0.016\">secondyear</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.19%); opacity: 0.83\" title=\"-0.047\">mba</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.54%); opacity: 0.81\" title=\"-0.018\">student</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.16%); opacity: 0.82\" title=\"-0.035\">said</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.02%); opacity: 0.84\" title=\"-0.055\">students</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.45%); opacity: 0.82\" title=\"-0.034\">able</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.25%); opacity: 0.81\" title=\"0.010\">really</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.45%); opacity: 0.83\" title=\"-0.052\">interesting</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.92%); opacity: 0.81\" title=\"0.008\">projects</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.26%); opacity: 0.80\" title=\"-0.007\">internships</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.08%); opacity: 0.81\" title=\"-0.020\">companies</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.67%); opacity: 0.82\" title=\"0.033\">able</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.24%); opacity: 0.83\" title=\"0.041\">work</span><span style=\"opacity: 0.80\"> apply </span><span style=\"background-color: hsl(0, 100.00%, 84.46%); opacity: 0.85\" title=\"-0.079\">learning</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.18%); opacity: 0.86\" title=\"-0.097\">school</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.09%); opacity: 0.80\" title=\"-0.001\">right</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.96%); opacity: 0.80\" title=\"0.004\">away</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.23%); opacity: 0.81\" title=\"-0.015\">exciting</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.29%); opacity: 0.83\" title=\"0.047\">although</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.52%); opacity: 0.82\" title=\"0.033\">program</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.12%); opacity: 0.84\" title=\"0.054\">early</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.39%); opacity: 0.80\" title=\"-0.003\">stages</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.02%); opacity: 0.80\" title=\"0.002\">ulrich</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.70%); opacity: 0.83\" title=\"0.044\">noted</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.13%); opacity: 0.84\" title=\"-0.061\">two</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.11%); opacity: 0.82\" title=\"-0.025\">potential</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.51%); opacity: 0.81\" title=\"-0.018\">plans</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.57%); opacity: 0.81\" title=\"0.013\">future</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.90%); opacity: 0.82\" title=\"0.026\">expansion</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.96%); opacity: 0.80\" title=\"-0.002\">may</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.78%); opacity: 0.83\" title=\"0.050\">undergraduate</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-0.306\">version</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 75.71%); opacity: 0.90\" title=\"-0.150\">would</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.11%); opacity: 0.81\" title=\"0.015\">meet</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.40%); opacity: 0.85\" title=\"-0.073\">spring</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.29%); opacity: 0.82\" title=\"0.024\">take</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.36%); opacity: 0.83\" title=\"0.046\">model</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 69.43%); opacity: 0.94\" title=\"-0.209\">parts</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.35%); opacity: 0.82\" title=\"0.024\">world</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.56%); opacity: 0.81\" title=\"0.009\">said</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "Explanation(estimator=\"SGDClassifier(alpha=0.001, average=False, class_weight=None,\\n              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\\n              l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=1000,\\n              n_iter_no_change=5, n_jobs=None, penalty='elasticnet',\\n              power_t=0.5, random_state=RandomState(MT19937) at 0x7F1BB8E1AEB8,\\n              shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\\n              warm_start=False)\", description=None, error=None, method='linear model', is_regression=False, targets=[TargetExplanation(target='low', feature_weights=FeatureWeights(pos=[FeatureWeight(feature='<BIAS>', weight=0.9100696702800124, std=None, value=1.0), FeatureWeight(feature='program', weight=0.26726662507566434, std=None, value=8.0), FeatureWeight(feature='give', weight=0.22463428913433023, std=None, value=3.0), FeatureWeight(feature='group', weight=0.22228769134139037, std=None, value=2.0), FeatureWeight(feature='semester', weight=0.1733449469754329, std=None, value=7.0), FeatureWeight(feature='model', weight=0.16666033911440348, std=None, value=1.0), FeatureWeight(feature='silicon', weight=0.16554029932791772, std=None, value=2.0), FeatureWeight(feature='also', weight=0.1528928635753966, std=None, value=3.0), FeatureWeight(feature='tour', weight=0.11460051142169139, std=None, value=1.0), FeatureWeight(feature='affinity', weight=0.1060769612436179, std=None, value=1.0), FeatureWeight(feature='tightly', weight=0.09964637436113209, std=None, value=1.0), FeatureWeight(feature='participants', weight=0.09545288690908249, std=None, value=1.0), FeatureWeight(feature='school recently', weight=0.09463191772279089, std=None, value=1.0), FeatureWeight(feature='summer', weight=0.0886560095136536, std=None, value=1.0), FeatureWeight(feature='time', weight=0.08687806092988862, std=None, value=1.0), FeatureWeight(feature='even going', weight=0.08641189057153362, std=None, value=1.0), FeatureWeight(feature='study school', weight=0.08280688007039995, std=None, value=1.0), FeatureWeight(feature='meet', weight=0.08067635263528598, std=None, value=1.0), FeatureWeight(feature='secondyear mba', weight=0.07839124391785618, std=None, value=5.0), FeatureWeight(feature='work', weight=0.0782659649009404, std=None, value=3.0), FeatureWeight(feature='valley semester', weight=0.07763143595650196, std=None, value=1.0), FeatureWeight(feature='regional', weight=0.07646226946052707, std=None, value=1.0), FeatureWeight(feature='order', weight=0.07556463940786178, std=None, value=1.0), FeatureWeight(feature='atmosphere', weight=0.07379750195150217, std=None, value=1.0), FeatureWeight(feature='conjunction', weight=0.07361750822895244, std=None, value=1.0), FeatureWeight(feature='fremont', weight=0.07264613666945902, std=None, value=1.0), FeatureWeight(feature='another', weight=0.07243946140891912, std=None, value=2.0), FeatureWeight(feature='program conjunction', weight=0.07226123902189036, std=None, value=1.0), FeatureWeight(feature='helpful', weight=0.07151040916405087, std=None, value=1.0), FeatureWeight(feature='time ever', weight=0.07008130647940997, std=None, value=1.0), FeatureWeight(feature='samuelson', weight=0.06705927790925889, std=None, value=2.0), FeatureWeight(feature='students career', weight=0.06535423269642279, std=None, value=1.0), FeatureWeight(feature='help', weight=0.0652245587282994, std=None, value=2.0), FeatureWeight(feature='said', weight=0.06455254398336702, std=None, value=7.0), FeatureWeight(feature='people working', weight=0.06369475012540421, std=None, value=1.0), FeatureWeight(feature='world', weight=0.06314412078543585, std=None, value=1.0), FeatureWeight(feature='strong', weight=0.06313475806240759, std=None, value=1.0), FeatureWeight(feature='already', weight=0.06263426761725878, std=None, value=1.0), FeatureWeight(feature='added', weight=0.06241455774379827, std=None, value=1.0), FeatureWeight(feature='powerful', weight=0.061089929823430617, std=None, value=1.0), FeatureWeight(feature='speakers', weight=0.06031063264003623, std=None, value=1.0), FeatureWeight(feature='study', weight=0.05942669496521657, std=None, value=2.0), FeatureWeight(feature='region', weight=0.05918621259868432, std=None, value=1.0), FeatureWeight(feature='highlighted', weight=0.0590820707599441, std=None, value=1.0), FeatureWeight(feature='stay said', weight=0.05880934858696588, std=None, value=1.0), FeatureWeight(feature='undergraduate', weight=0.05599727078898132, std=None, value=1.0), FeatureWeight(feature='one', weight=0.055557655184878665, std=None, value=1.0), FeatureWeight(feature='amazing katherine', weight=0.05531524567571103, std=None, value=1.0), FeatureWeight(feature='classroom instruction', weight=0.054285946245121675, std=None, value=1.0), FeatureWeight(feature='last', weight=0.05412189137565075, std=None, value=1.0), FeatureWeight(feature='early', weight=0.054061218891791996, std=None, value=1.0), FeatureWeight(feature='innovation karl', weight=0.053322601967004925, std=None, value=1.0), FeatureWeight(feature='jacob', weight=0.05326339837114409, std=None, value=1.0), FeatureWeight(feature='noted benefits', weight=0.051045400393700376, std=None, value=1.0), FeatureWeight(feature='launch', weight=0.05100390151133723, std=None, value=1.0), FeatureWeight(feature='ways', weight=0.0497929268561454, std=None, value=1.0), FeatureWeight(feature='addition', weight=0.049098229852153785, std=None, value=1.0), FeatureWeight(feature='career goals', weight=0.0488092213990353, std=None, value=1.0), FeatureWeight(feature='right', weight=0.048690356844973304, std=None, value=1.0), FeatureWeight(feature='take model', weight=0.0486811531276324, std=None, value=1.0), FeatureWeight(feature='experiences facility', weight=0.047802347891269865, std=None, value=1.0), FeatureWeight(feature='opened january', weight=0.04679682987524318, std=None, value=1.0), FeatureWeight(feature='although', weight=0.04661674549495406, std=None, value=1.0), FeatureWeight(feature='students blending', weight=0.04651615476905416, std=None, value=1.0), FeatureWeight(feature='ever', weight=0.04588773309220503, std=None, value=1.0), FeatureWeight(feature='unique', weight=0.04547278159518713, std=None, value=1.0), FeatureWeight(feature='economy', weight=0.04466034938537613, std=None, value=1.0), FeatureWeight(feature='us', weight=0.0437149542027292, std=None, value=1.0), FeatureWeight(feature='november', weight=0.04360904555072473, std=None, value=1.0), FeatureWeight(feature='ideas', weight=0.04332332709551176, std=None, value=1.0), FeatureWeight(feature='order develop', weight=0.042948513566085256, std=None, value=1.0), FeatureWeight(feature='featuring', weight=0.0428727203021617, std=None, value=1.0), FeatureWeight(feature='investors', weight=0.04247291274334186, std=None, value=1.0), FeatureWeight(feature='wharton school', weight=0.04237610990499314, std=None, value=1.0), FeatureWeight(feature='technologyrich', weight=0.04203574582901263, std=None, value=1.0), FeatureWeight(feature='focus', weight=0.0415381725058211, std=None, value=2.0), FeatureWeight(feature='area', weight=0.04107601105116419, std=None, value=2.0), FeatureWeight(feature='select', weight=0.04079781027801167, std=None, value=1.0), FeatureWeight(feature='integrated', weight=0.03982438456324684, std=None, value=1.0), FeatureWeight(feature='implementing', weight=0.03930094971942838, std=None, value=1.0), FeatureWeight(feature='technology', weight=0.039173817322561325, std=None, value=2.0), FeatureWeight(feature='integrated terms', weight=0.03742274350474669, std=None, value=1.0), FeatureWeight(feature='innovation', weight=0.03730493598268962, std=None, value=1.0), FeatureWeight(feature='needed', weight=0.0364829171696242, std=None, value=1.0), FeatureWeight(feature='designed', weight=0.035741787093687916, std=None, value=1.0), FeatureWeight(feature='perspective', weight=0.03562576978924079, std=None, value=1.0), FeatureWeight(feature='students ended', weight=0.035461914526325355, std=None, value=1.0), FeatureWeight(feature='pilot program', weight=0.0342592999201468, std=None, value=1.0), FeatureWeight(feature='stay', weight=0.0331314596828011, std=None, value=1.0), FeatureWeight(feature='really', weight=0.0330033468974179, std=None, value=1.0), FeatureWeight(feature='noted', weight=0.03270477279236251, std=None, value=2.0), FeatureWeight(feature='aspect', weight=0.031991020945287205, std=None, value=1.0), FeatureWeight(feature='projects internships', weight=0.03116612863344954, std=None, value=1.0), FeatureWeight(feature='dean innovation', weight=0.03073719885586583, std=None, value=1.0), FeatureWeight(feature='interests', weight=0.030570147169676716, std=None, value=1.0), FeatureWeight(feature='entrepreneurs see', weight=0.03044958413118598, std=None, value=1.0), FeatureWeight(feature='ended curriculum', weight=0.029018754794364443, std=None, value=1.0), FeatureWeight(feature='entrepreneurial culture', weight=0.028945592906550605, std=None, value=1.0), FeatureWeight(feature='projects', weight=0.028646549626549275, std=None, value=1.0), FeatureWeight(feature='noted two', weight=0.027770778920299166, std=None, value=1.0), FeatureWeight(feature='tours', weight=0.027599747408663666, std=None, value=1.0), FeatureWeight(feature='relationships', weight=0.02720823560274228, std=None, value=1.0), FeatureWeight(feature='helps', weight=0.027164839594210774, std=None, value=1.0), FeatureWeight(feature='study abroad', weight=0.026881500889629685, std=None, value=1.0), FeatureWeight(feature='facility', weight=0.026856259275586544, std=None, value=1.0), FeatureWeight(feature='semester application', weight=0.02668518390394538, std=None, value=1.0), FeatureWeight(feature='conduciveness rising', weight=0.025652476760772307, std=None, value=1.0), FeatureWeight(feature='advice', weight=0.025188155608387414, std=None, value=1.0), FeatureWeight(feature='talk professional', weight=0.023971982265639964, std=None, value=1.0), FeatureWeight(feature='bay', weight=0.02278107267730309, std=None, value=2.0), FeatureWeight(feature='ulrich', weight=0.021904987118936663, std=None, value=3.0), FeatureWeight(feature='immerse entrepreneurial', weight=0.021075399885862944, std=None, value=1.0), FeatureWeight(feature='took', weight=0.021003005387763264, std=None, value=1.0), FeatureWeight(feature='even', weight=0.020628090911364638, std=None, value=1.0), FeatureWeight(feature='focused', weight=0.020244791800545895, std=None, value=1.0), FeatureWeight(feature='thinking', weight=0.02021609500225023, std=None, value=1.0), FeatureWeight(feature='first', weight=0.02013139142822691, std=None, value=1.0), FeatureWeight(feature='particular', weight=0.019468232013438117, std=None, value=1.0), FeatureWeight(feature='away', weight=0.019063752529874144, std=None, value=1.0), FeatureWeight(feature='student program', weight=0.01899129930721981, std=None, value=1.0), FeatureWeight(feature='launched', weight=0.018921004498950365, std=None, value=1.0), FeatureWeight(feature='development', weight=0.01874510872633643, std=None, value=1.0), FeatureWeight(feature='companies able', weight=0.01778712734543961, std=None, value=1.0), FeatureWeight(feature='appealing aspect', weight=0.017605489861148547, std=None, value=1.0), FeatureWeight(feature='valley', weight=0.017481230860919794, std=None, value=2.0), FeatureWeight(feature='various kinds', weight=0.01736178514067248, std=None, value=1.0), FeatureWeight(feature='part', weight=0.016579060490277263, std=None, value=1.0), FeatureWeight(feature='create', weight=0.01647606016568939, std=None, value=1.0), FeatureWeight(feature='culture', weight=0.016046635698834452, std=None, value=1.0), FeatureWeight(feature='able work', weight=0.014783241493900649, std=None, value=1.0), FeatureWeight(feature='plans', weight=0.013763457087399603, std=None, value=2.0), FeatureWeight(feature='future expansion', weight=0.013194517917211587, std=None, value=1.0), FeatureWeight(feature='semester conduciveness', weight=0.012881929854634107, std=None, value=1.0), FeatureWeight(feature='expansion', weight=0.012717024122884661, std=None, value=1.0), FeatureWeight(feature='katherine', weight=0.01113278684025067, std=None, value=1.0), FeatureWeight(feature='opportunity cultivate', weight=0.010023485016098507, std=None, value=1.0), FeatureWeight(feature='demonstrate', weight=0.009553662554512173, std=None, value=1.0), FeatureWeight(feature='entrepreneurship technology', weight=0.009479012957175176, std=None, value=1.0), FeatureWeight(feature='needed demonstrate', weight=0.006464308073468632, std=None, value=1.0), FeatureWeight(feature='engagement', weight=0.005369637128185906, std=None, value=1.0), FeatureWeight(feature='questions', weight=0.004138408514677197, std=None, value=1.0), FeatureWeight(feature='said accelerating', weight=0.0031173852758484043, std=None, value=1.0), FeatureWeight(feature='stages', weight=0.002642961254196755, std=None, value=1.0)], neg=[FeatureWeight(feature='wharton', weight=-0.37937342830542153, std=None, value=3.0), FeatureWeight(feature='san francisco', weight=-0.19985984182844768, std=None, value=5.0), FeatureWeight(feature='mba', weight=-0.19443751352458655, std=None, value=5.0), FeatureWeight(feature='regional economy', weight=-0.18002277738078495, std=None, value=1.0), FeatureWeight(feature='company', weight=-0.17942783044538624, std=None, value=2.0), FeatureWeight(feature='model parts', weight=-0.16914676487899347, std=None, value=1.0), FeatureWeight(feature='version', weight=-0.16754113236565524, std=None, value=1.0), FeatureWeight(feature='silicon valley', weight=-0.15159691542422818, std=None, value=2.0), FeatureWeight(feature='san', weight=-0.14116146808597813, std=None, value=5.0), FeatureWeight(feature='career', weight=-0.13554193270038611, std=None, value=2.0), FeatureWeight(feature='version would', weight=-0.13268278043398712, std=None, value=1.0), FeatureWeight(feature='group secondyear', weight=-0.12712565363830303, std=None, value=1.0), FeatureWeight(feature='applicants', weight=-0.12275091023119804, std=None, value=1.0), FeatureWeight(feature='tightly integrated', weight=-0.10470190730967717, std=None, value=1.0), FeatureWeight(feature='said surrounded', weight=-0.10028400033397039, std=None, value=1.0), FeatureWeight(feature='tour tesla', weight=-0.09979997680656252, std=None, value=1.0), FeatureWeight(feature='according ulrich', weight=-0.096572829067686, std=None, value=1.0), FeatureWeight(feature='motors fremont', weight=-0.09330489702521068, std=None, value=1.0), FeatureWeight(feature='willing help', weight=-0.089500120926482, std=None, value=1.0), FeatureWeight(feature='two', weight=-0.08842621245666171, std=None, value=1.0), FeatureWeight(feature='process startups', weight=-0.08751772579095879, std=None, value=1.0), FeatureWeight(feature='campus', weight=-0.08430972176980273, std=None, value=1.0), FeatureWeight(feature='strengths', weight=-0.08326884638789783, std=None, value=1.0), FeatureWeight(feature='give advice', weight=-0.08263988200852734, std=None, value=1.0), FeatureWeight(feature='howell another', weight=-0.08197357153230711, std=None, value=1.0), FeatureWeight(feature='scheduled november', weight=-0.07876790477697039, std=None, value=1.0), FeatureWeight(feature='designed give', weight=-0.07808710277896319, std=None, value=1.0), FeatureWeight(feature='academic record', weight=-0.07508143678218465, std=None, value=1.0), FeatureWeight(feature='feed', weight=-0.07426841691055418, std=None, value=1.0), FeatureWeight(feature='course interests', weight=-0.07276812911367586, std=None, value=1.0), FeatureWeight(feature='already met', weight=-0.07216615390044254, std=None, value=1.0), FeatureWeight(feature='describe career', weight=-0.07151563518054535, std=None, value=1.0), FeatureWeight(feature='new san', weight=-0.06624089695017729, std=None, value=1.0), FeatureWeight(feature='application process', weight=-0.06445344395115227, std=None, value=1.0), FeatureWeight(feature='students needed', weight=-0.06410194822771265, std=None, value=1.0), FeatureWeight(feature='according', weight=-0.0621672297108227, std=None, value=1.0), FeatureWeight(feature='career course', weight=-0.06200294820391538, std=None, value=1.0), FeatureWeight(feature='coast appealing', weight=-0.059774491049960764, std=None, value=1.0), FeatureWeight(feature='vice dean', weight=-0.05967622796535419, std=None, value=1.0), FeatureWeight(feature='francisco secondyear', weight=-0.05955927387668763, std=None, value=1.0), FeatureWeight(feature='semester wharton', weight=-0.057324632623477624, std=None, value=2.0), FeatureWeight(feature='dean', weight=-0.05727109764448502, std=None, value=1.0), FeatureWeight(feature='activities', weight=-0.05718918720002715, std=None, value=1.0), FeatureWeight(feature='jeyakumar one', weight=-0.0570123876128327, std=None, value=1.0), FeatureWeight(feature='cohesive', weight=-0.05568230001308921, std=None, value=1.0), FeatureWeight(feature='took students', weight=-0.05554600014686191, std=None, value=1.0), FeatureWeight(feature='highlighted semester', weight=-0.05543377569962621, std=None, value=1.0), FeatureWeight(feature='also described', weight=-0.05403180393549529, std=None, value=1.0), FeatureWeight(feature='also main', weight=-0.05290349186400553, std=None, value=1.0), FeatureWeight(feature='consideration', weight=-0.052850507006269594, std=None, value=1.0), FeatureWeight(feature='school west', weight=-0.05282861389569072, std=None, value=1.0), FeatureWeight(feature='us develop', weight=-0.05245105865940664, std=None, value=1.0), FeatureWeight(feature='interesting projects', weight=-0.051957966896767974, std=None, value=1.0), FeatureWeight(feature='cultivate', weight=-0.05182900201659439, std=None, value=1.0), FeatureWeight(feature='atmosphere program', weight=-0.051276819909109615, std=None, value=1.0), FeatureWeight(feature='mba students', weight=-0.05088300605389936, std=None, value=2.0), FeatureWeight(feature='recently', weight=-0.050108000548787404, std=None, value=1.0), FeatureWeight(feature='school right', weight=-0.05006920576939176, std=None, value=1.0), FeatureWeight(feature='select group', weight=-0.05004123673978757, std=None, value=1.0), FeatureWeight(feature='various', weight=-0.0497592117797748, std=None, value=1.0), FeatureWeight(feature='extracurricular', weight=-0.04933190141428747, std=None, value=1.0), FeatureWeight(feature='jeyakumar', weight=-0.049278540206126036, std=None, value=2.0), FeatureWeight(feature='culture bay', weight=-0.04925228070785144, std=None, value=1.0), FeatureWeight(feature='ever group', weight=-0.049115826333692325, std=None, value=1.0), FeatureWeight(feature='bay area', weight=-0.0486448503264329, std=None, value=2.0), FeatureWeight(feature='program opportunity', weight=-0.048142798289680995, std=None, value=1.0), FeatureWeight(feature='meet spring', weight=-0.04785575289009464, std=None, value=1.0), FeatureWeight(feature='program already', weight=-0.04697906960023294, std=None, value=1.0), FeatureWeight(feature='learning school', weight=-0.046462468952315324, std=None, value=1.0), FeatureWeight(feature='experience definitely', weight=-0.045340313157428015, std=None, value=1.0), FeatureWeight(feature='one participants', weight=-0.045313780055905396, std=None, value=1.0), FeatureWeight(feature='students able', weight=-0.04499529966051227, std=None, value=2.0), FeatureWeight(feature='worked', weight=-0.044771670302290005, std=None, value=1.0), FeatureWeight(feature='focus featuring', weight=-0.044614627969838935, std=None, value=1.0), FeatureWeight(feature='firsthand', weight=-0.04264818478434261, std=None, value=1.0), FeatureWeight(feature='location fall', weight=-0.04180066933111615, std=None, value=1.0), FeatureWeight(feature='experience said', weight=-0.04048591122975174, std=None, value=1.0), FeatureWeight(feature='opportunity work', weight=-0.04032356097946145, std=None, value=1.0), FeatureWeight(feature='parts world', weight=-0.039547826962677245, std=None, value=1.0), FeatureWeight(feature='tours also', weight=-0.03861159362041025, std=None, value=1.0), FeatureWeight(feature='recently launched', weight=-0.03835172067129371, std=None, value=1.0), FeatureWeight(feature='featuring guest', weight=-0.038077581810153395, std=None, value=1.0), FeatureWeight(feature='asking', weight=-0.03795087941756696, std=None, value=1.0), FeatureWeight(feature='internships companies', weight=-0.03780624248081553, std=None, value=1.0), FeatureWeight(feature='see ecosystem', weight=-0.0376318827023686, std=None, value=1.0), FeatureWeight(feature='samuelson added', weight=-0.03752926034778456, std=None, value=1.0), FeatureWeight(feature='rising', weight=-0.03645954328900188, std=None, value=1.0), FeatureWeight(feature='linking content', weight=-0.03611066207354431, std=None, value=1.0), FeatureWeight(feature='jeyakumar plans', weight=-0.03504590443296246, std=None, value=1.0), FeatureWeight(feature='aspect program', weight=-0.03475065952515939, std=None, value=1.0), FeatureWeight(feature='mba student', weight=-0.03448692212732072, std=None, value=3.0), FeatureWeight(feature='goals explain', weight=-0.03395958752756661, std=None, value=1.0), FeatureWeight(feature='learning', weight=-0.032941338335043695, std=None, value=1.0), FeatureWeight(feature='grow addition', weight=-0.032821943474348, std=None, value=1.0), FeatureWeight(feature='students opportunity', weight=-0.03225875009981215, std=None, value=2.0), FeatureWeight(feature='said students', weight=-0.03223857901871969, std=None, value=1.0), FeatureWeight(feature='working', weight=-0.03219134856597971, std=None, value=1.0), FeatureWeight(feature='francisco campus', weight=-0.03210901495442791, std=None, value=1.0), FeatureWeight(feature='willing', weight=-0.031195310690591567, std=None, value=2.0), FeatureWeight(feature='focused entrepreneurship', weight=-0.03114863334678317, std=None, value=1.0), FeatureWeight(feature='definitely take', weight=-0.03070925512635981, std=None, value=1.0), FeatureWeight(feature='hopefully', weight=-0.03049508165639274, std=None, value=1.0), FeatureWeight(feature='extracurricular activities', weight=-0.030337076744606124, std=None, value=1.0), FeatureWeight(feature='ended', weight=-0.030206489117655645, std=None, value=1.0), FeatureWeight(feature='going', weight=-0.02995545253609357, std=None, value=3.0), FeatureWeight(feature='curriculum much', weight=-0.02951361918966088, std=None, value=1.0), FeatureWeight(feature='campus opened', weight=-0.02947055560735653, std=None, value=1.0), FeatureWeight(feature='program select', weight=-0.028601561064107838, std=None, value=1.0), FeatureWeight(feature='applicants describe', weight=-0.028445337792504848, std=None, value=1.0), FeatureWeight(feature='strong academic', weight=-0.02824121335090522, std=None, value=1.0), FeatureWeight(feature='met', weight=-0.027949833806645712, std=None, value=1.0), FeatureWeight(feature='cohesive educational', weight=-0.0266758333400234, std=None, value=1.0), FeatureWeight(feature='karl ulrich', weight=-0.026383487093261396, std=None, value=1.0), FeatureWeight(feature='helpful friendly', weight=-0.025796484999484115, std=None, value=1.0), FeatureWeight(feature='last summer', weight=-0.02577073516988471, std=None, value=1.0), FeatureWeight(feature='professional experiences', weight=-0.025270671029257473, std=None, value=1.0), FeatureWeight(feature='potential plans', weight=-0.024837357532659254, std=None, value=1.0), FeatureWeight(feature='spring take', weight=-0.02477338031088194, std=None, value=1.0), FeatureWeight(feature='location', weight=-0.023959544310033432, std=None, value=1.0), FeatureWeight(feature='fairly', weight=-0.023603999462656816, std=None, value=1.0), FeatureWeight(feature='advantage jacob', weight=-0.02359474976094598, std=None, value=1.0), FeatureWeight(feature='able really', weight=-0.022583767096183656, std=None, value=1.0), FeatureWeight(feature='give students', weight=-0.021966034541306603, std=None, value=2.0), FeatureWeight(feature='opportunity immerse', weight=-0.021574046016357495, std=None, value=1.0), FeatureWeight(feature='describe', weight=-0.021185196070846832, std=None, value=1.0), FeatureWeight(feature='semester program', weight=-0.01989503664603291, std=None, value=1.0), FeatureWeight(feature='blending classroom', weight=-0.019257607762975505, std=None, value=1.0), FeatureWeight(feature='added opportunity', weight=-0.018458819020568652, std=None, value=1.0), FeatureWeight(feature='would meet', weight=-0.017587938693135987, std=None, value=1.0), FeatureWeight(feature='areas experience', weight=-0.017431227746638658, std=None, value=1.0), FeatureWeight(feature='explain', weight=-0.017312210772566887, std=None, value=1.0), FeatureWeight(feature='invaluable even', weight=-0.0164479283773858, std=None, value=1.0), FeatureWeight(feature='consideration curriculum', weight=-0.015947527372472754, std=None, value=1.0), FeatureWeight(feature='said based', weight=-0.015806365720798746, std=None, value=1.0), FeatureWeight(feature='away exciting', weight=-0.014700606521296537, std=None, value=1.0), FeatureWeight(feature='student rajeev', weight=-0.014065046158120533, std=None, value=1.0), FeatureWeight(feature='said jeyakumar', weight=-0.013835924335609259, std=None, value=1.0), FeatureWeight(feature='plans launch', weight=-0.012497027829285547, std=None, value=1.0), FeatureWeight(feature='interests consideration', weight=-0.012439445916818821, std=None, value=1.0), FeatureWeight(feature='student said', weight=-0.012420682753060026, std=None, value=1.0), FeatureWeight(feature='summer based', weight=-0.009571474366840452, std=None, value=1.0), FeatureWeight(feature='francisco semester', weight=-0.00955513637876205, std=None, value=1.0), FeatureWeight(feature='classroom', weight=-0.007480359591549787, std=None, value=1.0), FeatureWeight(feature='undergraduate version', weight=-0.006168826236812136, std=None, value=1.0), FeatureWeight(feature='calif scheduled', weight=-0.006102633475028013, std=None, value=1.0), FeatureWeight(feature='stages ulrich', weight=-0.005767156941817956, std=None, value=1.0), FeatureWeight(feature='working areas', weight=-0.005407890179846465, std=None, value=1.0), FeatureWeight(feature='based', weight=-0.005147883101284379, std=None, value=3.0), FeatureWeight(feature='student', weight=-0.004682767035929066, std=None, value=3.0), FeatureWeight(feature='may', weight=-0.001677817998824346, std=None, value=1.0), FeatureWeight(feature='students unique', weight=-0.0015191581393290497, std=None, value=1.0)], pos_remaining=0, neg_remaining=0), proba=0.521458027486009, score=-0.08588486309596499, weighted_spans=WeightedSpans(docs_weighted_spans=[DocWeightedSpans(document='first time ever group secondyear mba students opportunity study abroad semester wharton school recently launched pilot program conjunction new san francisco campus opened january program select group students able study school west coast location fall semester program designed give students opportunity immerse entrepreneurial technologyrich environment silicon valley semester application process consisted questions asking applicants describe career goals explain semester san francisco would help grow addition students needed demonstrate strong academic record wharton vice dean innovation karl ulrich noted benefits implementing semester san francisco secondyear mba students blending classroom instruction extracurricular activities various kinds engagement regional economy hopefully create powerful cohesive educational experience said order develop curriculum san francisco semester wharton took students career course interests consideration curriculum fairly tightly integrated terms focus linking content course region ways said based affinity students ended curriculum much focused entrepreneurship technology also main strengths bay area according ulrich course particular focus featuring guest speakers san francisco talk professional experiences facility tours also part curriculum tour tesla motors fremont calif scheduled november secondyear mba student rajeev jeyakumar one participants program highlighted semester conduciveness rising entrepreneurs see ecosystem entrepreneurial culture bay area invaluable even going stay said jeyakumar plans launch company future also described helpful friendly atmosphere program already met people willing help investors willing give advice said accelerating development process startups going amazing katherine howell another secondyear mba student program opportunity cultivate relationships west coast appealing aspect program helps us develop surrounded people thinking ideas feed learn said surrounded people working areas experience definitely take advantage jacob samuelson added opportunity work companies based silicon valley give students unique firsthand perspective going work education technology company worked last summer based samuelson another secondyear mba student said students able really interesting projects internships companies able work apply learning school right away exciting although program early stages ulrich noted two potential plans future expansion may undergraduate version would meet spring take model parts world said', spans=[('first', [(0, 5)], 0.02013139142822691), ('time', [(6, 10)], 0.08687806092988862), ('ever', [(11, 15)], 0.04588773309220503), ('group', [(16, 21)], 0.22228769134139037), ('mba', [(33, 36)], -0.19443751352458655), ('study', [(58, 63)], 0.05942669496521657), ('semester', [(71, 79)], 0.1733449469754329), ('wharton', [(80, 87)], -0.37937342830542153), ('recently', [(95, 103)], -0.050108000548787404), ('launched', [(104, 112)], 0.018921004498950365), ('program', [(119, 126)], 0.26726662507566434), ('conjunction', [(127, 138)], 0.07361750822895244), ('san', [(143, 146)], -0.14116146808597813), ('campus', [(157, 163)], -0.08430972176980273), ('program', [(179, 186)], 0.26726662507566434), ('select', [(187, 193)], 0.04079781027801167), ('group', [(194, 199)], 0.22228769134139037), ('study', [(214, 219)], 0.05942669496521657), ('location', [(238, 246)], -0.023959544310033432), ('semester', [(252, 260)], 0.1733449469754329), ('program', [(261, 268)], 0.26726662507566434), ('designed', [(269, 277)], 0.035741787093687916), ('give', [(278, 282)], 0.22463428913433023), ('technologyrich', [(328, 342)], 0.04203574582901263), ('silicon', [(355, 362)], 0.16554029932791772), ('valley', [(363, 369)], 0.017481230860919794), ('semester', [(370, 378)], 0.1733449469754329), ('questions', [(409, 418)], 0.004138408514677197), ('asking', [(419, 425)], -0.03795087941756696), ('applicants', [(426, 436)], -0.12275091023119804), ('describe', [(437, 445)], -0.021185196070846832), ('career', [(446, 452)], -0.13554193270038611), ('explain', [(459, 466)], -0.017312210772566887), ('semester', [(467, 475)], 0.1733449469754329), ('san', [(476, 479)], -0.14116146808597813), ('help', [(496, 500)], 0.0652245587282994), ('addition', [(506, 514)], 0.049098229852153785), ('needed', [(524, 530)], 0.0364829171696242), ('demonstrate', [(531, 542)], 0.009553662554512173), ('strong', [(543, 549)], 0.06313475806240759), ('wharton', [(566, 573)], -0.37937342830542153), ('dean', [(579, 583)], -0.05727109764448502), ('innovation', [(584, 594)], 0.03730493598268962), ('ulrich', [(600, 606)], 0.021904987118936663), ('noted', [(607, 612)], 0.03270477279236251), ('implementing', [(622, 634)], 0.03930094971942838), ('semester', [(635, 643)], 0.1733449469754329), ('san', [(644, 647)], -0.14116146808597813), ('mba', [(669, 672)], -0.19443751352458655), ('classroom', [(691, 700)], -0.007480359591549787), ('extracurricular', [(713, 728)], -0.04933190141428747), ('activities', [(729, 739)], -0.05718918720002715), ('various', [(740, 747)], -0.0497592117797748), ('engagement', [(754, 764)], 0.005369637128185906), ('regional', [(765, 773)], 0.07646226946052707), ('economy', [(774, 781)], 0.04466034938537613), ('hopefully', [(782, 791)], -0.03049508165639274), ('create', [(792, 798)], 0.01647606016568939), ('powerful', [(799, 807)], 0.061089929823430617), ('cohesive', [(808, 816)], -0.05568230001308921), ('said', [(840, 844)], 0.06455254398336702), ('order', [(845, 850)], 0.07556463940786178), ('san', [(870, 873)], -0.14116146808597813), ('semester', [(884, 892)], 0.1733449469754329), ('wharton', [(893, 900)], -0.37937342830542153), ('took', [(901, 905)], 0.021003005387763264), ('career', [(915, 921)], -0.13554193270038611), ('interests', [(929, 938)], 0.030570147169676716), ('consideration', [(939, 952)], -0.052850507006269594), ('fairly', [(964, 970)], -0.023603999462656816), ('tightly', [(971, 978)], 0.09964637436113209), ('integrated', [(979, 989)], 0.03982438456324684), ('focus', [(996, 1001)], 0.0415381725058211), ('region', [(1025, 1031)], 0.05918621259868432), ('ways', [(1032, 1036)], 0.0497929268561454), ('said', [(1037, 1041)], 0.06455254398336702), ('based', [(1042, 1047)], -0.005147883101284379), ('affinity', [(1048, 1056)], 0.1060769612436179), ('ended', [(1066, 1071)], -0.030206489117655645), ('focused', [(1088, 1095)], 0.020244791800545895), ('technology', [(1113, 1123)], 0.039173817322561325), ('also', [(1124, 1128)], 0.1528928635753966), ('strengths', [(1134, 1143)], -0.08326884638789783), ('bay', [(1144, 1147)], 0.02278107267730309), ('area', [(1148, 1152)], 0.04107601105116419), ('according', [(1153, 1162)], -0.0621672297108227), ('ulrich', [(1163, 1169)], 0.021904987118936663), ('particular', [(1177, 1187)], 0.019468232013438117), ('focus', [(1188, 1193)], 0.0415381725058211), ('featuring', [(1194, 1203)], 0.0428727203021617), ('speakers', [(1210, 1218)], 0.06031063264003623), ('san', [(1219, 1222)], -0.14116146808597813), ('facility', [(1263, 1271)], 0.026856259275586544), ('tours', [(1272, 1277)], 0.027599747408663666), ('also', [(1278, 1282)], 0.1528928635753966), ('part', [(1283, 1287)], 0.016579060490277263), ('tour', [(1299, 1303)], 0.11460051142169139), ('fremont', [(1317, 1324)], 0.07264613666945902), ('november', [(1341, 1349)], 0.04360904555072473), ('mba', [(1361, 1364)], -0.19443751352458655), ('student', [(1365, 1372)], -0.004682767035929066), ('jeyakumar', [(1380, 1389)], -0.049278540206126036), ('one', [(1390, 1393)], 0.055557655184878665), ('participants', [(1394, 1406)], 0.09545288690908249), ('program', [(1407, 1414)], 0.26726662507566434), ('highlighted', [(1415, 1426)], 0.0590820707599441), ('semester', [(1427, 1435)], 0.1733449469754329), ('rising', [(1450, 1456)], -0.03645954328900188), ('culture', [(1501, 1508)], 0.016046635698834452), ('bay', [(1509, 1512)], 0.02278107267730309), ('area', [(1513, 1517)], 0.04107601105116419), ('even', [(1529, 1533)], 0.020628090911364638), ('going', [(1534, 1539)], -0.02995545253609357), ('stay', [(1540, 1544)], 0.0331314596828011), ('said', [(1545, 1549)], 0.06455254398336702), ('jeyakumar', [(1550, 1559)], -0.049278540206126036), ('plans', [(1560, 1565)], 0.013763457087399603), ('launch', [(1566, 1572)], 0.05100390151133723), ('company', [(1573, 1580)], -0.17942783044538624), ('also', [(1588, 1592)], 0.1528928635753966), ('helpful', [(1603, 1610)], 0.07151040916405087), ('atmosphere', [(1620, 1630)], 0.07379750195150217), ('program', [(1631, 1638)], 0.26726662507566434), ('already', [(1639, 1646)], 0.06263426761725878), ('met', [(1647, 1650)], -0.027949833806645712), ('willing', [(1658, 1665)], -0.031195310690591567), ('help', [(1666, 1670)], 0.0652245587282994), ('investors', [(1671, 1680)], 0.04247291274334186), ('willing', [(1681, 1688)], -0.031195310690591567), ('give', [(1689, 1693)], 0.22463428913433023), ('advice', [(1694, 1700)], 0.025188155608387414), ('said', [(1701, 1705)], 0.06455254398336702), ('development', [(1719, 1730)], 0.01874510872633643), ('going', [(1748, 1753)], -0.02995545253609357), ('katherine', [(1762, 1771)], 0.01113278684025067), ('another', [(1779, 1786)], 0.07243946140891912), ('mba', [(1798, 1801)], -0.19443751352458655), ('student', [(1802, 1809)], -0.004682767035929066), ('program', [(1810, 1817)], 0.26726662507566434), ('cultivate', [(1830, 1839)], -0.05182900201659439), ('relationships', [(1840, 1853)], 0.02720823560274228), ('aspect', [(1875, 1881)], 0.031991020945287205), ('program', [(1882, 1889)], 0.26726662507566434), ('helps', [(1890, 1895)], 0.027164839594210774), ('us', [(1896, 1898)], 0.0437149542027292), ('thinking', [(1925, 1933)], 0.02021609500225023), ('ideas', [(1934, 1939)], 0.04332332709551176), ('feed', [(1940, 1944)], -0.07426841691055418), ('said', [(1951, 1955)], 0.06455254398336702), ('working', [(1974, 1981)], -0.03219134856597971), ('jacob', [(2025, 2030)], 0.05326339837114409), ('samuelson', [(2031, 2040)], 0.06705927790925889), ('added', [(2041, 2046)], 0.06241455774379827), ('work', [(2059, 2063)], 0.0782659649009404), ('based', [(2074, 2079)], -0.005147883101284379), ('silicon', [(2080, 2087)], 0.16554029932791772), ('valley', [(2088, 2094)], 0.017481230860919794), ('give', [(2095, 2099)], 0.22463428913433023), ('unique', [(2109, 2115)], 0.04547278159518713), ('firsthand', [(2116, 2125)], -0.04264818478434261), ('perspective', [(2126, 2137)], 0.03562576978924079), ('going', [(2138, 2143)], -0.02995545253609357), ('work', [(2144, 2148)], 0.0782659649009404), ('technology', [(2159, 2169)], 0.039173817322561325), ('company', [(2170, 2177)], -0.17942783044538624), ('worked', [(2178, 2184)], -0.044771670302290005), ('last', [(2185, 2189)], 0.05412189137565075), ('summer', [(2190, 2196)], 0.0886560095136536), ('based', [(2197, 2202)], -0.005147883101284379), ('samuelson', [(2203, 2212)], 0.06705927790925889), ('another', [(2213, 2220)], 0.07243946140891912), ('mba', [(2232, 2235)], -0.19443751352458655), ('student', [(2236, 2243)], -0.004682767035929066), ('said', [(2244, 2248)], 0.06455254398336702), ('really', [(2263, 2269)], 0.0330033468974179), ('projects', [(2282, 2290)], 0.028646549626549275), ('work', [(2318, 2322)], 0.0782659649009404), ('learning', [(2329, 2337)], -0.032941338335043695), ('right', [(2345, 2350)], 0.048690356844973304), ('away', [(2351, 2355)], 0.019063752529874144), ('although', [(2365, 2373)], 0.04661674549495406), ('program', [(2374, 2381)], 0.26726662507566434), ('early', [(2382, 2387)], 0.054061218891791996), ('stages', [(2388, 2394)], 0.002642961254196755), ('ulrich', [(2395, 2401)], 0.021904987118936663), ('noted', [(2402, 2407)], 0.03270477279236251), ('two', [(2408, 2411)], -0.08842621245666171), ('plans', [(2422, 2427)], 0.013763457087399603), ('expansion', [(2435, 2444)], 0.012717024122884661), ('may', [(2445, 2448)], -0.001677817998824346), ('undergraduate', [(2449, 2462)], 0.05599727078898132), ('version', [(2463, 2470)], -0.16754113236565524), ('meet', [(2477, 2481)], 0.08067635263528598), ('model', [(2494, 2499)], 0.16666033911440348), ('world', [(2506, 2511)], 0.06314412078543585), ('said', [(2512, 2516)], 0.06455254398336702), ('time ever', [(6, 10), (11, 15)], 0.07008130647940997), ('ever group', [(11, 15), (16, 21)], -0.049115826333692325), ('group secondyear', [(16, 21), (22, 32)], -0.12712565363830303), ('secondyear mba', [(22, 32), (33, 36)], 0.07839124391785618), ('mba students', [(33, 36), (37, 45)], -0.05088300605389936), ('students opportunity', [(37, 45), (46, 57)], -0.03225875009981215), ('study abroad', [(58, 63), (64, 70)], 0.026881500889629685), ('semester wharton', [(71, 79), (80, 87)], -0.057324632623477624), ('wharton school', [(80, 87), (88, 94)], 0.04237610990499314), ('school recently', [(88, 94), (95, 103)], 0.09463191772279089), ('recently launched', [(95, 103), (104, 112)], -0.03835172067129371), ('pilot program', [(113, 118), (119, 126)], 0.0342592999201468), ('program conjunction', [(119, 126), (127, 138)], 0.07226123902189036), ('new san', [(139, 142), (143, 146)], -0.06624089695017729), ('san francisco', [(143, 146), (147, 156)], -0.19985984182844768), ('francisco campus', [(147, 156), (157, 163)], -0.03210901495442791), ('campus opened', [(157, 163), (164, 170)], -0.02947055560735653), ('opened january', [(164, 170), (171, 178)], 0.04679682987524318), ('program select', [(179, 186), (187, 193)], -0.028601561064107838), ('select group', [(187, 193), (194, 199)], -0.05004123673978757), ('students able', [(200, 208), (209, 213)], -0.04499529966051227), ('study school', [(214, 219), (220, 226)], 0.08280688007039995), ('school west', [(220, 226), (227, 231)], -0.05282861389569072), ('location fall', [(238, 246), (247, 251)], -0.04180066933111615), ('semester program', [(252, 260), (261, 268)], -0.01989503664603291), ('designed give', [(269, 277), (278, 282)], -0.07808710277896319), ('give students', [(278, 282), (283, 291)], -0.021966034541306603), ('students opportunity', [(283, 291), (292, 303)], -0.03225875009981215), ('opportunity immerse', [(292, 303), (304, 311)], -0.021574046016357495), ('immerse entrepreneurial', [(304, 311), (312, 327)], 0.021075399885862944), ('silicon valley', [(355, 362), (363, 369)], -0.15159691542422818), ('valley semester', [(363, 369), (370, 378)], 0.07763143595650196), ('semester application', [(370, 378), (379, 390)], 0.02668518390394538), ('application process', [(379, 390), (391, 398)], -0.06445344395115227), ('applicants describe', [(426, 436), (437, 445)], -0.028445337792504848), ('describe career', [(437, 445), (446, 452)], -0.07151563518054535), ('career goals', [(446, 452), (453, 458)], 0.0488092213990353), ('goals explain', [(453, 458), (459, 466)], -0.03395958752756661), ('san francisco', [(476, 479), (480, 489)], -0.19985984182844768), ('grow addition', [(501, 505), (506, 514)], -0.032821943474348), ('students needed', [(515, 523), (524, 530)], -0.06410194822771265), ('needed demonstrate', [(524, 530), (531, 542)], 0.006464308073468632), ('strong academic', [(543, 549), (550, 558)], -0.02824121335090522), ('academic record', [(550, 558), (559, 565)], -0.07508143678218465), ('vice dean', [(574, 578), (579, 583)], -0.05967622796535419), ('dean innovation', [(579, 583), (584, 594)], 0.03073719885586583), ('innovation karl', [(584, 594), (595, 599)], 0.053322601967004925), ('karl ulrich', [(595, 599), (600, 606)], -0.026383487093261396), ('noted benefits', [(607, 612), (613, 621)], 0.051045400393700376), ('san francisco', [(644, 647), (648, 657)], -0.19985984182844768), ('francisco secondyear', [(648, 657), (658, 668)], -0.05955927387668763), ('secondyear mba', [(658, 668), (669, 672)], 0.07839124391785618), ('mba students', [(669, 672), (673, 681)], -0.05088300605389936), ('students blending', [(673, 681), (682, 690)], 0.04651615476905416), ('blending classroom', [(682, 690), (691, 700)], -0.019257607762975505), ('classroom instruction', [(691, 700), (701, 712)], 0.054285946245121675), ('extracurricular activities', [(713, 728), (729, 739)], -0.030337076744606124), ('various kinds', [(740, 747), (748, 753)], 0.01736178514067248), ('regional economy', [(765, 773), (774, 781)], -0.18002277738078495), ('cohesive educational', [(808, 816), (817, 828)], -0.0266758333400234), ('experience said', [(829, 839), (840, 844)], -0.04048591122975174), ('order develop', [(845, 850), (851, 858)], 0.042948513566085256), ('san francisco', [(870, 873), (874, 883)], -0.19985984182844768), ('francisco semester', [(874, 883), (884, 892)], -0.00955513637876205), ('semester wharton', [(884, 892), (893, 900)], -0.057324632623477624), ('took students', [(901, 905), (906, 914)], -0.05554600014686191), ('students career', [(906, 914), (915, 921)], 0.06535423269642279), ('career course', [(915, 921), (922, 928)], -0.06200294820391538), ('course interests', [(922, 928), (929, 938)], -0.07276812911367586), ('interests consideration', [(929, 938), (939, 952)], -0.012439445916818821), ('consideration curriculum', [(939, 952), (953, 963)], -0.015947527372472754), ('tightly integrated', [(971, 978), (979, 989)], -0.10470190730967717), ('integrated terms', [(979, 989), (990, 995)], 0.03742274350474669), ('linking content', [(1002, 1009), (1010, 1017)], -0.03611066207354431), ('said based', [(1037, 1041), (1042, 1047)], -0.015806365720798746), ('students ended', [(1057, 1065), (1066, 1071)], 0.035461914526325355), ('ended curriculum', [(1066, 1071), (1072, 1082)], 0.029018754794364443), ('curriculum much', [(1072, 1082), (1083, 1087)], -0.02951361918966088), ('focused entrepreneurship', [(1088, 1095), (1096, 1112)], -0.03114863334678317), ('entrepreneurship technology', [(1096, 1112), (1113, 1123)], 0.009479012957175176), ('also main', [(1124, 1128), (1129, 1133)], -0.05290349186400553), ('bay area', [(1144, 1147), (1148, 1152)], -0.0486448503264329), ('according ulrich', [(1153, 1162), (1163, 1169)], -0.096572829067686), ('focus featuring', [(1188, 1193), (1194, 1203)], -0.044614627969838935), ('featuring guest', [(1194, 1203), (1204, 1209)], -0.038077581810153395), ('san francisco', [(1219, 1222), (1223, 1232)], -0.19985984182844768), ('talk professional', [(1233, 1237), (1238, 1250)], 0.023971982265639964), ('professional experiences', [(1238, 1250), (1251, 1262)], -0.025270671029257473), ('experiences facility', [(1251, 1262), (1263, 1271)], 0.047802347891269865), ('tours also', [(1272, 1277), (1278, 1282)], -0.03861159362041025), ('tour tesla', [(1299, 1303), (1304, 1309)], -0.09979997680656252), ('motors fremont', [(1310, 1316), (1317, 1324)], -0.09330489702521068), ('calif scheduled', [(1325, 1330), (1331, 1340)], -0.006102633475028013), ('scheduled november', [(1331, 1340), (1341, 1349)], -0.07876790477697039), ('secondyear mba', [(1350, 1360), (1361, 1364)], 0.07839124391785618), ('mba student', [(1361, 1364), (1365, 1372)], -0.03448692212732072), ('student rajeev', [(1365, 1372), (1373, 1379)], -0.014065046158120533), ('jeyakumar one', [(1380, 1389), (1390, 1393)], -0.0570123876128327), ('one participants', [(1390, 1393), (1394, 1406)], -0.045313780055905396), ('highlighted semester', [(1415, 1426), (1427, 1435)], -0.05543377569962621), ('semester conduciveness', [(1427, 1435), (1436, 1449)], 0.012881929854634107), ('conduciveness rising', [(1436, 1449), (1450, 1456)], 0.025652476760772307), ('entrepreneurs see', [(1457, 1470), (1471, 1474)], 0.03044958413118598), ('see ecosystem', [(1471, 1474), (1475, 1484)], -0.0376318827023686), ('entrepreneurial culture', [(1485, 1500), (1501, 1508)], 0.028945592906550605), ('culture bay', [(1501, 1508), (1509, 1512)], -0.04925228070785144), ('bay area', [(1509, 1512), (1513, 1517)], -0.0486448503264329), ('invaluable even', [(1518, 1528), (1529, 1533)], -0.0164479283773858), ('even going', [(1529, 1533), (1534, 1539)], 0.08641189057153362), ('stay said', [(1540, 1544), (1545, 1549)], 0.05880934858696588), ('said jeyakumar', [(1545, 1549), (1550, 1559)], -0.013835924335609259), ('jeyakumar plans', [(1550, 1559), (1560, 1565)], -0.03504590443296246), ('plans launch', [(1560, 1565), (1566, 1572)], -0.012497027829285547), ('also described', [(1588, 1592), (1593, 1602)], -0.05403180393549529), ('helpful friendly', [(1603, 1610), (1611, 1619)], -0.025796484999484115), ('atmosphere program', [(1620, 1630), (1631, 1638)], -0.051276819909109615), ('program already', [(1631, 1638), (1639, 1646)], -0.04697906960023294), ('already met', [(1639, 1646), (1647, 1650)], -0.07216615390044254), ('willing help', [(1658, 1665), (1666, 1670)], -0.089500120926482), ('give advice', [(1689, 1693), (1694, 1700)], -0.08263988200852734), ('said accelerating', [(1701, 1705), (1706, 1718)], 0.0031173852758484043), ('process startups', [(1731, 1738), (1739, 1747)], -0.08751772579095879), ('amazing katherine', [(1754, 1761), (1762, 1771)], 0.05531524567571103), ('howell another', [(1772, 1778), (1779, 1786)], -0.08197357153230711), ('secondyear mba', [(1787, 1797), (1798, 1801)], 0.07839124391785618), ('mba student', [(1798, 1801), (1802, 1809)], -0.03448692212732072), ('student program', [(1802, 1809), (1810, 1817)], 0.01899129930721981), ('program opportunity', [(1810, 1817), (1818, 1829)], -0.048142798289680995), ('opportunity cultivate', [(1818, 1829), (1830, 1839)], 0.010023485016098507), ('coast appealing', [(1859, 1864), (1865, 1874)], -0.059774491049960764), ('appealing aspect', [(1865, 1874), (1875, 1881)], 0.017605489861148547), ('aspect program', [(1875, 1881), (1882, 1889)], -0.03475065952515939), ('us develop', [(1896, 1898), (1899, 1906)], -0.05245105865940664), ('said surrounded', [(1951, 1955), (1956, 1966)], -0.10028400033397039), ('people working', [(1967, 1973), (1974, 1981)], 0.06369475012540421), ('working areas', [(1974, 1981), (1982, 1987)], -0.005407890179846465), ('areas experience', [(1982, 1987), (1988, 1998)], -0.017431227746638658), ('experience definitely', [(1988, 1998), (1999, 2009)], -0.045340313157428015), ('definitely take', [(1999, 2009), (2010, 2014)], -0.03070925512635981), ('advantage jacob', [(2015, 2024), (2025, 2030)], -0.02359474976094598), ('samuelson added', [(2031, 2040), (2041, 2046)], -0.03752926034778456), ('added opportunity', [(2041, 2046), (2047, 2058)], -0.018458819020568652), ('opportunity work', [(2047, 2058), (2059, 2063)], -0.04032356097946145), ('silicon valley', [(2080, 2087), (2088, 2094)], -0.15159691542422818), ('give students', [(2095, 2099), (2100, 2108)], -0.021966034541306603), ('students unique', [(2100, 2108), (2109, 2115)], -0.0015191581393290497), ('last summer', [(2185, 2189), (2190, 2196)], -0.02577073516988471), ('summer based', [(2190, 2196), (2197, 2202)], -0.009571474366840452), ('secondyear mba', [(2221, 2231), (2232, 2235)], 0.07839124391785618), ('mba student', [(2232, 2235), (2236, 2243)], -0.03448692212732072), ('student said', [(2236, 2243), (2244, 2248)], -0.012420682753060026), ('said students', [(2244, 2248), (2249, 2257)], -0.03223857901871969), ('students able', [(2249, 2257), (2258, 2262)], -0.04499529966051227), ('able really', [(2258, 2262), (2263, 2269)], -0.022583767096183656), ('interesting projects', [(2270, 2281), (2282, 2290)], -0.051957966896767974), ('projects internships', [(2282, 2290), (2291, 2302)], 0.03116612863344954), ('internships companies', [(2291, 2302), (2303, 2312)], -0.03780624248081553), ('companies able', [(2303, 2312), (2313, 2317)], 0.01778712734543961), ('able work', [(2313, 2317), (2318, 2322)], 0.014783241493900649), ('learning school', [(2329, 2337), (2338, 2344)], -0.046462468952315324), ('school right', [(2338, 2344), (2345, 2350)], -0.05006920576939176), ('away exciting', [(2351, 2355), (2356, 2364)], -0.014700606521296537), ('stages ulrich', [(2388, 2394), (2395, 2401)], -0.005767156941817956), ('noted two', [(2402, 2407), (2408, 2411)], 0.027770778920299166), ('potential plans', [(2412, 2421), (2422, 2427)], -0.024837357532659254), ('future expansion', [(2428, 2434), (2435, 2444)], 0.013194517917211587), ('undergraduate version', [(2449, 2462), (2463, 2470)], -0.006168826236812136), ('version would', [(2463, 2470), (2471, 2476)], -0.13268278043398712), ('would meet', [(2471, 2476), (2477, 2481)], -0.017587938693135987), ('meet spring', [(2477, 2481), (2482, 2488)], -0.04785575289009464), ('spring take', [(2482, 2488), (2489, 2493)], -0.02477338031088194), ('take model', [(2489, 2493), (2494, 2499)], 0.0486811531276324), ('model parts', [(2494, 2499), (2500, 2505)], -0.16914676487899347), ('parts world', [(2500, 2505), (2506, 2511)], -0.039547826962677245)], preserve_density=False, vec_name=None)], other=FeatureWeights(pos=[FeatureWeight(feature='<BIAS>', weight=0.9100696702800124, std=None, value=1.0)], neg=[FeatureWeight(feature=<FormattedFeatureName 'Highlighted in text (sum)'>, weight=-0.8241848071840454, std=None, value=None)], pos_remaining=0, neg_remaining=0)), heatmap=None)], feature_importances=None, decision_tree=None, highlight_spaces=None, transition_features=None, image=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "z-_nPc0_8LND",
        "outputId": "2665c000-2c2b-4ad8-8ca5-05d5afbbdace"
      },
      "source": [
        "te.explain_weights(target_names = ['low', 'high'])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "            \n",
              "                \n",
              "                \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=high\n",
              "    \n",
              "</b>\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
              "                    Weight<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 88.34%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.465\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        back\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 92.92%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.228\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        penn\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 93.24%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.213\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        arts sciences\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 93.45%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.204\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        tweet\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 93.57%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.199\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        said\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 93.67%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.194\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        received\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 93.78%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.189\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        emergency\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 93.99%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.180\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        university\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 94.16%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.173\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        pm\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 94.21%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.171\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        operations\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 94.51%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.158\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        according\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 94.64%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.153\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        noon\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 94.64%); border: none;\">\n",
              "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
              "                    <i>&hellip; 62 more positive &hellip;</i>\n",
              "                </td>\n",
              "            </tr>\n",
              "        \n",
              "\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 94.70%); border: none;\">\n",
              "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
              "                    <i>&hellip; 58 more negative &hellip;</i>\n",
              "                </td>\n",
              "            </tr>\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 94.70%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.151\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        director student\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 94.60%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.155\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        close\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 93.95%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.182\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        director\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 92.90%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.229\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        events\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 92.87%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.230\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        around\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 92.20%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.262\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        philadelphia\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 91.38%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.302\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        emergency information\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.005\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "            \n",
              "        \n",
              "\n",
              "        \n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "Explanation(estimator=\"SGDClassifier(alpha=0.001, average=False, class_weight=None,\\n              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\\n              l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=1000,\\n              n_iter_no_change=5, n_jobs=None, penalty='elasticnet',\\n              power_t=0.5, random_state=RandomState(MT19937) at 0x7F1BB8E1AA98,\\n              shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\\n              warm_start=False)\", description=\"\\nFeatures with largest coefficients.\\nCaveats:\\n1. Be careful with features which are not\\n   independent - weights don't show their importance.\\n2. If scale of input features is different then scale of coefficients\\n   will also be different, making direct comparison between coefficient values\\n   incorrect.\\n3. Depending on regularization, rare features sometimes may have high\\n   coefficients; this doesn't mean they contribute much to the\\n   classification result for most examples.\\n\", error=None, method='linear model', is_regression=False, targets=[TargetExplanation(target='high', feature_weights=FeatureWeights(pos=[FeatureWeight(feature='back', weight=0.46460585912514923, std=None, value=None), FeatureWeight(feature='penn', weight=0.22812865635742785, std=None, value=None), FeatureWeight(feature='arts sciences', weight=0.21348123617734024, std=None, value=None), FeatureWeight(feature='tweet', weight=0.20402853180754027, std=None, value=None), FeatureWeight(feature='said', weight=0.19874737681116383, std=None, value=None), FeatureWeight(feature='received', weight=0.1943734321213178, std=None, value=None), FeatureWeight(feature='emergency', weight=0.1893864051431553, std=None, value=None), FeatureWeight(feature='university', weight=0.18016843451751283, std=None, value=None), FeatureWeight(feature='pm', weight=0.17296360130298763, std=None, value=None), FeatureWeight(feature='operations', weight=0.17107896490725139, std=None, value=None), FeatureWeight(feature='according', weight=0.15829456811253237, std=None, value=None), FeatureWeight(feature='noon', weight=0.15305975321772025, std=None, value=None)], neg=[FeatureWeight(feature='<BIAS>', weight=-1.0048567422168526, std=None, value=None), FeatureWeight(feature='emergency information', weight=-0.30216246084592135, std=None, value=None), FeatureWeight(feature='philadelphia', weight=-0.26184173360030305, std=None, value=None), FeatureWeight(feature='around', weight=-0.23044809040924957, std=None, value=None), FeatureWeight(feature='events', weight=-0.22890388819604798, std=None, value=None), FeatureWeight(feature='director', weight=-0.1818762428200143, std=None, value=None), FeatureWeight(feature='close', weight=-0.15490537352427183, std=None, value=None), FeatureWeight(feature='director student', weight=-0.15052744157363443, std=None, value=None)], pos_remaining=62, neg_remaining=58), proba=None, score=None, weighted_spans=None, heatmap=None)], feature_importances=None, decision_tree=None, highlight_spaces=None, transition_features=None, image=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    }
  ]
}