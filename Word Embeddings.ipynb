{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec and Deep Learning Article Views\n",
    "\n",
    "https://towardsdatascience.com/machine-learning-word-embedding-sentiment-classification-using-keras-b83c28087456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:14:40.643020Z",
     "start_time": "2020-12-11T01:14:40.604727Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import math\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T07:41:19.930986Z",
     "start_time": "2020-12-02T07:41:15.854593Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-17bb7203622b>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:14:44.711343Z",
     "start_time": "2020-12-11T01:14:42.500438Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:14:44.803413Z",
     "start_time": "2020-12-11T01:14:44.713303Z"
    }
   },
   "outputs": [],
   "source": [
    "content = train['content'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:14:46.261904Z",
     "start_time": "2020-12-11T01:14:46.239961Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocessing(content_list):\n",
    "    \n",
    "    processed_list = []\n",
    "    \n",
    "    for line in tqdm(content_list):\n",
    "        tokens = word_tokenize(line)\n",
    "        # Convert to lower case\n",
    "        tokens = [w.lower() for w in tokens]\n",
    "        # Remove punctuation\n",
    "        table = str.maketrans('', '', string.punctuation)\n",
    "        stripped = [w.translate(table) for w in tokens]\n",
    "        # Remove remaining tokens that are not alphabetic\n",
    "        words = [word for word in stripped if word.isalpha()]\n",
    "        # Filter out stopwords\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        words = [w for w in words if not w in stop_words]\n",
    "        \n",
    "        processed_list.append(words)\n",
    "        \n",
    "    return processed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T13:08:55.439752Z",
     "start_time": "2020-12-09T13:08:55.426789Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocessing - to remove length-1 words, and remove non-alphabet symbols\n",
    "def preprocessing(titles_array):\n",
    "\n",
    "    processed_array = []\n",
    "    \n",
    "    for title in tqdm(titles_array):\n",
    "        \n",
    "        # remove other non-alphabets symbols with space (i.e. keep only alphabets and whitespaces).\n",
    "        processed = re.sub('[^a-zA-Z ]', '', title)\n",
    "        \n",
    "        words = processed.split()\n",
    "        \n",
    "        # keep words that have length of more than 1 (e.g. gb, bb), remove those with length 1.\n",
    "        processed_array.append(' '.join([word for word in words if len(word) > 1]))\n",
    "    \n",
    "    return processed_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:16:02.801571Z",
     "start_time": "2020-12-11T01:14:47.552999Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 16772/16772 [01:15<00:00, 223.61it/s]\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing the words\n",
    "train['processed_content'] = preprocessing(train['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Word2Vec Model\n",
    "\n",
    "Word2Vec is a static word-embedding.\n",
    "\n",
    "**Getting from Word Embedding to Doc Embedding**\n",
    "\n",
    "- https://towardsdatascience.com/nlp-performance-of-different-word-embeddings-on-text-classification-de648c6262b\n",
    "- 3 methods:\n",
    "1. Simple Averaging of Word Embedding\n",
    "2. TF-IDF Weighted Averaging on Word Embedding\n",
    "3. Directly leverage Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:16:02.817547Z",
     "start_time": "2020-12-11T01:16:02.803562Z"
    }
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:16:50.025331Z",
     "start_time": "2020-12-11T01:16:02.821539Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences = train['processed_content'], size = EMBEDDING_DIM, min_count = 1, window = 5, workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:16:50.040328Z",
     "start_time": "2020-12-11T01:16:50.027333Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 111788\n"
     ]
    }
   ],
   "source": [
    "# Vocab size\n",
    "words = list(model.wv.vocab)\n",
    "print('Vocabulary size: {}'.format(len(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:19:46.225042Z",
     "start_time": "2020-12-11T01:19:46.201608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('steinbergdietrich', 0.7880867123603821),\n",
       " ('houston', 0.7732806205749512),\n",
       " ('stiteler', 0.7369509935379028),\n",
       " ('tangen', 0.7138106822967529),\n",
       " ('meyerson', 0.7133698463439941),\n",
       " ('golkin', 0.7085722088813782),\n",
       " ('fagin', 0.7020806074142456),\n",
       " ('fisherbennett', 0.700007975101471),\n",
       " ('gathwala', 0.6967608332633972),\n",
       " ('skirkanich', 0.6869189143180847)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the model\n",
    "model.wv.most_similar('huntsman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:17:39.671037Z",
     "start_time": "2020-12-11T01:17:39.650093Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ifc', 0.9987518191337585),\n",
       " ('sorority', 0.9928473830223083),\n",
       " ('mgc', 0.9732818603515625),\n",
       " ('panhellenic', 0.9669802188873291),\n",
       " ('sororities', 0.9545149207115173),\n",
       " ('greek', 0.9544658064842224),\n",
       " ('panhel', 0.9450474381446838),\n",
       " ('chapter', 0.9426577091217041),\n",
       " ('chapters', 0.9415575265884399),\n",
       " ('recruitment', 0.9344643354415894)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Doing math on the word vectors\n",
    "model.wv.most_similar_cosmul(positive = ['fraternity', 'female'], negative = ['male'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T06:23:54.242999Z",
     "start_time": "2020-12-02T06:23:45.103128Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "filename = 'word2vec_train2.txt'\n",
    "model.wv.save_word2vec_format(filename, binary = False)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
